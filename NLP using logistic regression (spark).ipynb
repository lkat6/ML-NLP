{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b4d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlflow\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import NGram, VectorAssembler, StopWordsRemover, HashingTF, IDF, Tokenizer, StringIndexer, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName('Twitter Sentiment Analysis') \\\n",
    "        .getOrCreate()\n",
    "print('Session created')\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "\n",
    "## import training dataset from AWS S3\n",
    "tweets = spark.read.option('header',True).csv('/mnt/twitter_sentiment_dataset')\n",
    "\n",
    "\n",
    "tweets = tweets.select('sentiment', F.col('SentimentText').alias('tweet'))\n",
    "\n",
    "## data cleaning\n",
    "tweets_clean   = tweets.withColumn('tweet', F.regexp_replace('tweet', r\"http\\S+\", \"\")) \\\n",
    "                   .withColumn('tweet', F.regexp_replace('tweet', r\"[^a-zA-z]\", \" \")) \\\n",
    "                   .withColumn('tweet', F.regexp_replace('tweet', r\"\\s+\", \" \")) \\\n",
    "                   .withColumn('tweet', F.lower('tweet')) \\\n",
    "                   .withColumn('tweet', F.trim('tweet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e11d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentiment Analysis using LogisticRegression\n",
    "\n",
    "# Use 90% cases for training, 10% cases for testing\n",
    "train, test = tweets_clean.randomSplit([0.9, 0.1], seed=41)\n",
    "\n",
    "\n",
    "# Create transformers for the ML pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"tokens\")\n",
    "stopword_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")\n",
    "cv = CountVectorizer(vocabSize=2**16, inputCol=\"filtered\", outputCol='cv')\n",
    "idf = IDF(inputCol='cv', outputCol=\"1gram_idf\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "assembler = VectorAssembler(inputCols=[\"1gram_idf\"], outputCol=\"features\")\n",
    "label_encoder= StringIndexer(inputCol = \"sentiment\", outputCol = \"label\")\n",
    "# create the trainer and set its parameters\n",
    "\n",
    "##MPC = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "lr = LogisticRegression()\n",
    "pipeline = Pipeline(stages=[tokenizer, stopword_remover, cv, idf, assembler, label_encoder, lr])\n",
    "\n",
    "\n",
    "## Model tunning\n",
    "paramGrid = ParamGridBuilder()\\\n",
    ".addGrid(lr.maxIter, [50])\\\n",
    "  .build()\n",
    "  ##   \\\n",
    "    \n",
    " ##   \n",
    "  \n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "## Training and cross validation\n",
    "tvs = TrainValidationSplit(estimator=pipeline,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=evaluator,\n",
    "                           parallelism=10,\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)\n",
    "\n",
    "tvs_model = tvs.fit(train)\n",
    "predictions = tvs_model.transform(test)\n",
    "##tvs_model.transform(test)\\\n",
    "##   .select(\"features\", \"label\", \"prediction\")\\\n",
    "##    .show()\n",
    "##evaluator.evaluate(predictions.select(\"prediction\", \"label\"))\n",
    "## predictionAndLabels = predictions.select(\"prediction\", \"label\")\n",
    "##evaluator =  BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "##MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(test.count())\n",
    "\n",
    "\n",
    "print(\"Accuracy Score: {0:.4f}\".format(accuracy))\n",
    "##Accuracy Score: 0.7761\n",
    "##Command took 53.44 minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
